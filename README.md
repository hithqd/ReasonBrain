# Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning


<div align="center">
  
[![arXiv](https://img.shields.io/badge/arXiv%20paper-2502.11079-b31b1b.svg)](https://arxiv.org/abs/2506.18851)&nbsp;
[![project page](https://img.shields.io/badge/Project_page-More_visualizations-green)](https://)&nbsp;
</div>

> [**Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning**](https://arxiv.org/abs/2502.11079)<br>
> [Qingdong He](https://scholar.google.com/citations?user=gUJWww0AAAAJ&hl=zh-CN)<sup> * </sup>, [Xueqin Chen](https://scholar.google.com/citations?user=6F-iHFsAAAAJ&hl=zh-CN)<sup> * </sup>, [Tianxiang Ma](https://tianxiangma.github.io/)<sup> * </sup>, [Lijie Liu](https://liulj13.github.io/)<sup> * </sup>, [Mingcong Liu](https://onion-liu.github.io), Yi Zhang, Gen Li, Xinghui Li, Siyu Zhou, [Qian He](https://scholar.google.com/citations?user=9rWWCgUAAAAJ), Xinglong Wu
> <br><sup> * </sup>Equal contribution,<sup> &dagger; </sup>Project lead
> <br>Intelligent Creation Lab, ByteDance<br>


<!-- # Phantom-Data
Phantom-Data: Towards a General Subject-Consistent Video Generation Dataset -->
## üìë Todo List
- [ ] We will release the code, model and dataset, on Huggingface before September 2025.



## ‚≠ê Citation

If Phantom-Data is helpful, please help to ‚≠ê the repo.

If you find this project useful for your research, please consider citing our [paper](https://arxiv.org/abs/2506.18851).

### BibTeX
```bibtex
@article{chen2025phantom-data,
      title={Phantom-Data: Towards a General Subject-Consistent Video Generation Dataset},
      author={Chen, Zhuowei and Li, Bingchuan and Ma, Tianxiang and Liu, Lijie and Liu, Mingcong and Zhang, Yi and Li, Gen and Li, Xinghui and Zhou, Siyu and He, Qian and Wu, Xinglong},
      journal={arXiv preprint arXiv:2506.18851},
      year={2025}
    }
```

## üìß Contact
If you have any comments or questions regarding this open-source project, please open a new issue or contact [Qingdong He](yingcaihe@tencent.com).
